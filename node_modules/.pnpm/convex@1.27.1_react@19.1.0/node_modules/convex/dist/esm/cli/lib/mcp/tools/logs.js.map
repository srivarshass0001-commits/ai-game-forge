{
  "version": 3,
  "sources": ["../../../../../../src/cli/lib/mcp/tools/logs.ts"],
  "sourcesContent": ["import { z } from \"zod\";\nimport { ConvexTool } from \"./index.js\";\nimport { loadSelectedDeploymentCredentials } from \"../../api.js\";\nimport { getDeploymentSelection } from \"../../deploymentSelection.js\";\nimport { deploymentFetch } from \"../../utils/utils.js\";\nimport { components } from \"../../generatedLogStreamApi.js\";\n\nconst inputSchema = z.object({\n  deploymentSelector: z\n    .string()\n    .describe(\"Deployment selector (from the status tool) to read logs from.\"),\n  cursor: z\n    .number()\n    .optional()\n    .describe(\n      \"Optional cursor (in ms) to start reading from. Use 0 to read from the beginning.\",\n    ),\n  entriesLimit: z\n    .number()\n    .int()\n    .positive()\n    .max(1000)\n    .optional()\n    .describe(\n      \"Maximum number of log entries to return (from the end). If omitted, returns all available in this chunk.\",\n    ),\n  tokensLimit: z\n    .number()\n    .int()\n    .positive()\n    .default(20000)\n    .optional()\n    .describe(\n      \"Approximate maximum number of tokens to return (applied to the JSON payload). Defaults to 20000.\",\n    ),\n});\n\nconst outputSchema = z.object({\n  entries: z.array(z.any()),\n  newCursor: z.number(),\n});\n\nconst logsResponseSchema = outputSchema;\n\ntype LogEntry = components[\"schemas\"][\"LogStreamEvent\"];\n\nconst description = `\nFetch a chunk of recent log entries from your Convex deployment.\n\nReturns a batch of UDF execution log entries and a new cursor you can use to\nrequest the next batch. This tool does not tail; it performs a single fetch.\n`.trim();\n\nexport const LogsTool: ConvexTool<typeof inputSchema, typeof outputSchema> = {\n  name: \"logs\",\n  description,\n  inputSchema,\n  outputSchema,\n  handler: async (ctx, args) => {\n    const { projectDir, deployment } = await ctx.decodeDeploymentSelector(\n      args.deploymentSelector,\n    );\n    process.chdir(projectDir);\n    const deploymentSelection = await getDeploymentSelection(ctx, ctx.options);\n    const credentials = await loadSelectedDeploymentCredentials(\n      ctx,\n      deploymentSelection,\n      deployment,\n    );\n\n    const fetch = deploymentFetch(ctx, {\n      deploymentUrl: credentials.url,\n      adminKey: credentials.adminKey,\n    });\n\n    const cursor = args.cursor ?? 0;\n    const response = await fetch(`/api/stream_function_logs?cursor=${cursor}`, {\n      method: \"GET\",\n    });\n\n    if (!response.ok) {\n      return await ctx.crash({\n        exitCode: 1,\n        errorType: \"fatal\",\n        printedMessage: `HTTP error ${response.status}: ${await response.text()}`,\n      });\n    }\n\n    const { entries, newCursor } = await response\n      .json()\n      .then(logsResponseSchema.parse);\n\n    return {\n      entries: limitLogs({\n        entries,\n        tokensLimit: args.tokensLimit ?? 20000,\n        entriesLimit: args.entriesLimit ?? entries.length,\n      }),\n      newCursor,\n    };\n  },\n};\n\nexport function limitLogs({\n  entries,\n  tokensLimit,\n  entriesLimit,\n}: {\n  entries: LogEntry[];\n  tokensLimit: number;\n  entriesLimit: number;\n}): LogEntry[] {\n  // 1) Apply entries limit first so we cut off neatly at entry boundaries (latest entries kept)\n  const limitedByEntries = entries.slice(entries.length - entriesLimit);\n\n  // 2) Apply token limit by iterating over log lines from newest to oldest and\n  //    only include lines while within token budget. We cut off at the nearest log line.\n  const limitedByTokens = limitEntriesByTokenBudget({\n    entries: limitedByEntries,\n    tokensLimit,\n  });\n\n  return limitedByTokens;\n}\n\nfunction limitEntriesByTokenBudget({\n  entries,\n  tokensLimit,\n}: {\n  entries: LogEntry[];\n  tokensLimit: number;\n}): LogEntry[] {\n  const result: LogEntry[] = [];\n  let tokens = 0;\n  for (const entry of entries) {\n    const entryString = JSON.stringify(entry);\n    const entryTokens = estimateTokenCount(entryString);\n    tokens += entryTokens;\n    if (tokens > tokensLimit) break;\n    result.push(entry);\n  }\n  return result;\n}\n\nfunction estimateTokenCount(entryString: string): number {\n  return entryString.length * 0.33;\n}\n\nexport function formatEntriesTerse(entries: LogEntry[]): string[] {\n  return entries\n    .map((entry) => {\n      const ts = entry.timestamp;\n\n      switch (entry.topic) {\n        case \"console\": {\n          return `${ts} ${entry.function.type} ${entry.function.path} ${entry.message}`;\n        }\n        case \"verification\": {\n          return `${entry.message}`;\n        }\n        case \"function_execution\": {\n          return `${entry.function.type} ${entry.function.path}`;\n        }\n        case \"audit_log\": {\n          return `${entry.audit_log_action}`;\n        }\n        case \"scheduler_stats\": {\n          return `${entry.num_running_jobs} running jobs`;\n        }\n        case \"scheduled_job_lag\": {\n          // skip it\n          return null;\n        }\n        default: {\n          entry satisfies never;\n          return null;\n        }\n      }\n    })\n    .filter((x): x is string => !!x);\n}\n"],
  "mappings": ";AAAA,SAAS,SAAS;AAElB,SAAS,yCAAyC;AAClD,SAAS,8BAA8B;AACvC,SAAS,uBAAuB;AAGhC,MAAM,cAAc,EAAE,OAAO;AAAA,EAC3B,oBAAoB,EACjB,OAAO,EACP,SAAS,+DAA+D;AAAA,EAC3E,QAAQ,EACL,OAAO,EACP,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EACF,cAAc,EACX,OAAO,EACP,IAAI,EACJ,SAAS,EACT,IAAI,GAAI,EACR,SAAS,EACT;AAAA,IACC;AAAA,EACF;AAAA,EACF,aAAa,EACV,OAAO,EACP,IAAI,EACJ,SAAS,EACT,QAAQ,GAAK,EACb,SAAS,EACT;AAAA,IACC;AAAA,EACF;AACJ,CAAC;AAED,MAAM,eAAe,EAAE,OAAO;AAAA,EAC5B,SAAS,EAAE,MAAM,EAAE,IAAI,CAAC;AAAA,EACxB,WAAW,EAAE,OAAO;AACtB,CAAC;AAED,MAAM,qBAAqB;AAI3B,MAAM,cAAc;AAAA;AAAA;AAAA;AAAA;AAAA,EAKlB,KAAK;AAEA,aAAM,WAAgE;AAAA,EAC3E,MAAM;AAAA,EACN;AAAA,EACA;AAAA,EACA;AAAA,EACA,SAAS,OAAO,KAAK,SAAS;AAC5B,UAAM,EAAE,YAAY,WAAW,IAAI,MAAM,IAAI;AAAA,MAC3C,KAAK;AAAA,IACP;AACA,YAAQ,MAAM,UAAU;AACxB,UAAM,sBAAsB,MAAM,uBAAuB,KAAK,IAAI,OAAO;AACzE,UAAM,cAAc,MAAM;AAAA,MACxB;AAAA,MACA;AAAA,MACA;AAAA,IACF;AAEA,UAAM,QAAQ,gBAAgB,KAAK;AAAA,MACjC,eAAe,YAAY;AAAA,MAC3B,UAAU,YAAY;AAAA,IACxB,CAAC;AAED,UAAM,SAAS,KAAK,UAAU;AAC9B,UAAM,WAAW,MAAM,MAAM,oCAAoC,MAAM,IAAI;AAAA,MACzE,QAAQ;AAAA,IACV,CAAC;AAED,QAAI,CAAC,SAAS,IAAI;AAChB,aAAO,MAAM,IAAI,MAAM;AAAA,QACrB,UAAU;AAAA,QACV,WAAW;AAAA,QACX,gBAAgB,cAAc,SAAS,MAAM,KAAK,MAAM,SAAS,KAAK,CAAC;AAAA,MACzE,CAAC;AAAA,IACH;AAEA,UAAM,EAAE,SAAS,UAAU,IAAI,MAAM,SAClC,KAAK,EACL,KAAK,mBAAmB,KAAK;AAEhC,WAAO;AAAA,MACL,SAAS,UAAU;AAAA,QACjB;AAAA,QACA,aAAa,KAAK,eAAe;AAAA,QACjC,cAAc,KAAK,gBAAgB,QAAQ;AAAA,MAC7C,CAAC;AAAA,MACD;AAAA,IACF;AAAA,EACF;AACF;AAEO,gBAAS,UAAU;AAAA,EACxB;AAAA,EACA;AAAA,EACA;AACF,GAIe;AAEb,QAAM,mBAAmB,QAAQ,MAAM,QAAQ,SAAS,YAAY;AAIpE,QAAM,kBAAkB,0BAA0B;AAAA,IAChD,SAAS;AAAA,IACT;AAAA,EACF,CAAC;AAED,SAAO;AACT;AAEA,SAAS,0BAA0B;AAAA,EACjC;AAAA,EACA;AACF,GAGe;AACb,QAAM,SAAqB,CAAC;AAC5B,MAAI,SAAS;AACb,aAAW,SAAS,SAAS;AAC3B,UAAM,cAAc,KAAK,UAAU,KAAK;AACxC,UAAM,cAAc,mBAAmB,WAAW;AAClD,cAAU;AACV,QAAI,SAAS,YAAa;AAC1B,WAAO,KAAK,KAAK;AAAA,EACnB;AACA,SAAO;AACT;AAEA,SAAS,mBAAmB,aAA6B;AACvD,SAAO,YAAY,SAAS;AAC9B;AAEO,gBAAS,mBAAmB,SAA+B;AAChE,SAAO,QACJ,IAAI,CAAC,UAAU;AACd,UAAM,KAAK,MAAM;AAEjB,YAAQ,MAAM,OAAO;AAAA,MACnB,KAAK,WAAW;AACd,eAAO,GAAG,EAAE,IAAI,MAAM,SAAS,IAAI,IAAI,MAAM,SAAS,IAAI,IAAI,MAAM,OAAO;AAAA,MAC7E;AAAA,MACA,KAAK,gBAAgB;AACnB,eAAO,GAAG,MAAM,OAAO;AAAA,MACzB;AAAA,MACA,KAAK,sBAAsB;AACzB,eAAO,GAAG,MAAM,SAAS,IAAI,IAAI,MAAM,SAAS,IAAI;AAAA,MACtD;AAAA,MACA,KAAK,aAAa;AAChB,eAAO,GAAG,MAAM,gBAAgB;AAAA,MAClC;AAAA,MACA,KAAK,mBAAmB;AACtB,eAAO,GAAG,MAAM,gBAAgB;AAAA,MAClC;AAAA,MACA,KAAK,qBAAqB;AAExB,eAAO;AAAA,MACT;AAAA,MACA,SAAS;AACP;AACA,eAAO;AAAA,MACT;AAAA,IACF;AAAA,EACF,CAAC,EACA,OAAO,CAAC,MAAmB,CAAC,CAAC,CAAC;AACnC;",
  "names": []
}
